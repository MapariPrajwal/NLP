{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2qMJKVAKbBO2lh9OGbIkJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MapariPrajwal/NLP/blob/main/language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "an9BHo62vZKm"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"I love natural language processing\",\n",
        "    \"Natural language processing is fun\",\n",
        "    \"Language models are powerful tools\",\n",
        "    \"Tasks such as next word predicstion\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def preprocess(corpus):\n",
        "    processed_corpus = []\n",
        "    for sentence in corpus:\n",
        "        sentence = sentence.lower()\n",
        "        sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "        words = sentence.split()\n",
        "        processed_corpus.append(words)\n",
        "    return processed_corpus\n",
        "\n",
        "processed_corpus = preprocess(corpus)\n"
      ],
      "metadata": {
        "id": "fFQansOMvhPB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ngrams(corpus, n):\n",
        "    ngrams = []\n",
        "    for sentence in corpus:\n",
        "        for i in range(len(sentence) - n + 1):\n",
        "            ngram = tuple(sentence[i:i+n])\n",
        "            ngrams.append(ngram)\n",
        "    return ngrams\n",
        "\n",
        "unigrams = [word for sentence in processed_corpus for word in sentence]\n",
        "bigrams = generate_ngrams(processed_corpus, 2)\n",
        "trigrams = generate_ngrams(processed_corpus, 3)\n",
        "\n",
        "print(\"Unigrams:\", unigrams)\n",
        "print(\"Bigrams:\", bigrams)\n",
        "print(\"Trigrams:\", trigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEebExWHvhhR",
        "outputId": "37439b88-d1dc-48bb-e8f1-6f33926168ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams: ['i', 'love', 'natural', 'language', 'processing', 'natural', 'language', 'processing', 'is', 'fun', 'language', 'models', 'are', 'powerful', 'tools', 'tools', 'like', 'chatgpt', 'assist', 'in', 'various', 'tasks', 'tasks', 'such', 'as', 'next', 'word', 'prediction']\n",
            "Bigrams: [('i', 'love'), ('love', 'natural'), ('natural', 'language'), ('language', 'processing'), ('natural', 'language'), ('language', 'processing'), ('processing', 'is'), ('is', 'fun'), ('language', 'models'), ('models', 'are'), ('are', 'powerful'), ('powerful', 'tools'), ('tools', 'like'), ('like', 'chatgpt'), ('chatgpt', 'assist'), ('assist', 'in'), ('in', 'various'), ('various', 'tasks'), ('tasks', 'such'), ('such', 'as'), ('as', 'next'), ('next', 'word'), ('word', 'prediction')]\n",
            "Trigrams: [('i', 'love', 'natural'), ('love', 'natural', 'language'), ('natural', 'language', 'processing'), ('natural', 'language', 'processing'), ('language', 'processing', 'is'), ('processing', 'is', 'fun'), ('language', 'models', 'are'), ('models', 'are', 'powerful'), ('are', 'powerful', 'tools'), ('tools', 'like', 'chatgpt'), ('like', 'chatgpt', 'assist'), ('chatgpt', 'assist', 'in'), ('assist', 'in', 'various'), ('in', 'various', 'tasks'), ('tasks', 'such', 'as'), ('such', 'as', 'next'), ('as', 'next', 'word'), ('next', 'word', 'prediction')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def add_one_smoothing(ngrams):\n",
        "    ngram_counts = Counter(ngrams)\n",
        "    vocabulary_size = len(set(ngrams))\n",
        "    smoothed_counts = {}\n",
        "    for ngram, count in ngram_counts.items():\n",
        "        smoothed_counts[ngram] = (count + 1) / (ngram_counts[ngram[:-1]] + vocabulary_size)\n",
        "    return smoothed_counts\n",
        "\n",
        "smoothed_bigrams = add_one_smoothing(bigrams)\n",
        "smoothed_trigrams = add_one_smoothing(trigrams)\n",
        "\n",
        "print(\"Smoothed Bigrams:\", smoothed_bigrams)\n",
        "print(\"Smoothed Trigrams:\", smoothed_trigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcJcg5nbvo8Y",
        "outputId": "16b5924a-f1d0-4d9d-e537-c31eb27da600"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoothed Bigrams: {('i', 'love'): 0.09523809523809523, ('love', 'natural'): 0.09523809523809523, ('natural', 'language'): 0.14285714285714285, ('language', 'processing'): 0.14285714285714285, ('processing', 'is'): 0.09523809523809523, ('is', 'fun'): 0.09523809523809523, ('language', 'models'): 0.09523809523809523, ('models', 'are'): 0.09523809523809523, ('are', 'powerful'): 0.09523809523809523, ('powerful', 'tools'): 0.09523809523809523, ('tools', 'like'): 0.09523809523809523, ('like', 'chatgpt'): 0.09523809523809523, ('chatgpt', 'assist'): 0.09523809523809523, ('assist', 'in'): 0.09523809523809523, ('in', 'various'): 0.09523809523809523, ('various', 'tasks'): 0.09523809523809523, ('tasks', 'such'): 0.09523809523809523, ('such', 'as'): 0.09523809523809523, ('as', 'next'): 0.09523809523809523, ('next', 'word'): 0.09523809523809523, ('word', 'prediction'): 0.09523809523809523}\n",
            "Smoothed Trigrams: {('i', 'love', 'natural'): 0.11764705882352941, ('love', 'natural', 'language'): 0.11764705882352941, ('natural', 'language', 'processing'): 0.17647058823529413, ('language', 'processing', 'is'): 0.11764705882352941, ('processing', 'is', 'fun'): 0.11764705882352941, ('language', 'models', 'are'): 0.11764705882352941, ('models', 'are', 'powerful'): 0.11764705882352941, ('are', 'powerful', 'tools'): 0.11764705882352941, ('tools', 'like', 'chatgpt'): 0.11764705882352941, ('like', 'chatgpt', 'assist'): 0.11764705882352941, ('chatgpt', 'assist', 'in'): 0.11764705882352941, ('assist', 'in', 'various'): 0.11764705882352941, ('in', 'various', 'tasks'): 0.11764705882352941, ('tasks', 'such', 'as'): 0.11764705882352941, ('such', 'as', 'next'): 0.11764705882352941, ('as', 'next', 'word'): 0.11764705882352941, ('next', 'word', 'prediction'): 0.11764705882352941}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(prefix, smoothed_ngrams):\n",
        "    candidates = [(ngram[-1], prob) for ngram, prob in smoothed_ngrams.items() if ngram[:-1] == tuple(prefix)]\n",
        "    candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "    return candidates[0][0] if candidates else None\n",
        "\n",
        "prefix = [\"natural\", \"language\"]\n",
        "next_word = predict_next_word(prefix, smoothed_trigrams) or predict_next_word(prefix[-1:], smoothed_bigrams)\n",
        "print(\"Next word prediction:\", next_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-TIMrZ-vqWu",
        "outputId": "8a42cf4b-832f-47cc-fdcf-1ce1a8da9342"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next word prediction: processing\n"
          ]
        }
      ]
    }
  ]
}